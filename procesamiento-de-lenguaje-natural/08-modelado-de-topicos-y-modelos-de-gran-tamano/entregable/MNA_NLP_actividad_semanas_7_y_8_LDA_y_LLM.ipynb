{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hVND8xY2OKY"
   },
   "source": [
    "# **Procesamiento de Lenguaje Natural**\n",
    "\n",
    "## Maestría en Inteligencia Artificial Aplicada\n",
    "#### Tecnológico de Monterrey\n",
    "#### Prof Luis Eduardo Falcón Morales\n",
    "\n",
    "### **Adtividad en Equipos Semanas 7 y 8 : LDA y LMM audio-a-texto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aimHVFOv23lm"
   },
   "source": [
    "* **Nombres y matrículas:**\n",
    "\n",
    "  * A00378771 - Hiram Garcia Austria\n",
    "  * A01281536 - Joaquín Díaz Hernández\n",
    "  * A01796568 - Jesús Antonio López Wayas\n",
    "  * A01795624 - Victor Hugo Vázquez Herrera\n",
    "\n",
    "* **Número de Equipo: 36**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jimvsiVgjMg"
   },
   "source": [
    "* ##### **En cada ejercicio pueden importar los paquetes o librerías que requieran.**\n",
    "\n",
    "* ##### **En cada ejercicio pueden incluir las celdas y líneas de código que deseen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "executionInfo": {
     "elapsed": 4852,
     "status": "error",
     "timestamp": 1749408505338,
     "user": {
      "displayName": "Jesús Antonio López Wayas",
      "userId": "16819167153657833693"
     },
     "user_tz": 360
    },
    "id": "4B5z1qSTzmC2",
    "outputId": "fe1788a6-f411-4620-a6eb-a4a43e22a664"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hille\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importamos OpenAI para usar la API de OpenAI\n",
    "from openai import OpenAI\n",
    "import openai # Usamos esta tambien porque sino no carga bien la anterior\n",
    "\n",
    "import pickle # Usamos pickle para guardar los resultados de la API de OpenAI\n",
    "import json # Usamos json para guardar los procesamientos de los resultados de la API de OpenAI\n",
    "import os # Usamos os para manejar rutas y archivos\n",
    "import re # Usamos re para manejar expresiones regulares\n",
    "import requests # Usamos requests para hacer peticiones HTTP y descargar archivos\n",
    "\n",
    "import gensim # Usamos gensim para el procesamiento de lenguaje natural\n",
    "import gensim.corpora as corpora # Usamos gensim.corpora para manejar el diccionario y el corpus\n",
    "from gensim.models.coherencemodel import CoherenceModel # Usamos CohcerenceModel para evalaur el resultado de nuestro model\n",
    "\n",
    "import nltk # Usamos nltk para el procesamiento de lenguaje natural\n",
    "nltk.download('stopwords') # Descargamos las stopwords de NLTK para el español\n",
    "\n",
    "from nltk.corpus import stopwords # Importamos las stopwords en español de NLTK\n",
    "\n",
    "stop_words_es = stopwords.words('spanish') # Definimos las stopwords en español"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Bfs5Zxc9j7Uf"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # Usamos la clave de API de OpenAI desde las variables de entorno\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BtP-Sk0DT-M"
   },
   "source": [
    "# **Ejercicio 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oh78pKeMghfe"
   },
   "source": [
    "* #### **Liga de los audios de las fábulas de Esopo:** https://www.gutenberg.org/ebooks/21144\n",
    "\n",
    "* #### **Descargar los 10 archivos de audio solicitados: 1, 4, 5, 6, 14, 22, 24, 25, 26, 27.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "SZYKUntlzmC3",
    "outputId": "a7b0e852-3202-473c-8b2f-7a456f513e9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Archivos de audio a procesar ---\n",
      "21144-01.mp3\n",
      "21144-04.mp3\n",
      "21144-05.mp3\n",
      "21144-06.mp3\n",
      "21144-14.mp3\n",
      "21144-22.mp3\n",
      "21144-24.mp3\n",
      "21144-25.mp3\n",
      "21144-26.mp3\n",
      "21144-27.mp3\n",
      "\n",
      "--- Iniciando descarga de audios ---\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-01.mp3 a audios_descargados\\21144-01.mp3\n",
      "Descarga completada: 21144-01.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-04.mp3 a audios_descargados\\21144-04.mp3\n",
      "Descarga completada: 21144-04.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-05.mp3 a audios_descargados\\21144-05.mp3\n",
      "Descarga completada: 21144-05.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-06.mp3 a audios_descargados\\21144-06.mp3\n",
      "Descarga completada: 21144-06.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-14.mp3 a audios_descargados\\21144-14.mp3\n",
      "Descarga completada: 21144-14.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-22.mp3 a audios_descargados\\21144-22.mp3\n",
      "Descarga completada: 21144-22.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-24.mp3 a audios_descargados\\21144-24.mp3\n",
      "Descarga completada: 21144-24.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-25.mp3 a audios_descargados\\21144-25.mp3\n",
      "Descarga completada: 21144-25.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-26.mp3 a audios_descargados\\21144-26.mp3\n",
      "Descarga completada: 21144-26.mp3\n",
      "Descargando: https://www.gutenberg.org/files/21144/mp3/21144-27.mp3 a audios_descargados\\21144-27.mp3\n",
      "Descarga completada: 21144-27.mp3\n",
      "\n",
      "--- Proceso de descarga de audios finalizado. ---\n"
     ]
    }
   ],
   "source": [
    "# Definimos los números de los archivos de audio que vamos a descargar\n",
    "audio_numbers = [1, 4, 5, 6, 14, 22, 24, 25, 26, 27]\n",
    "\n",
    "# Definimos la ruta base para los archivos de audio\n",
    "path_to_audio_file = \"https://www.gutenberg.org/files/21144/mp3\"\n",
    "# Definimos el directorio donde se guardarán los archivos de audio descargados\n",
    "download_directory = \"audios_descargados\"\n",
    "\n",
    "list_of_audio_file_names = [] # Lista para almacenar los nombres de los archivos de audio\n",
    "# Iteramos sobre los números de audio y formateamos los nombres de los archivos\n",
    "for number in audio_numbers:\n",
    "    list_of_audio_file_names.append(f\"21144-{number:02d}.mp3\")\n",
    "\n",
    "print(\"--- Archivos de audio a procesar ---\")\n",
    "# Mostramos los nombres de los archivos de audio que vamos a procesar\n",
    "for audio_file_name in list_of_audio_file_names:\n",
    "    print(audio_file_name)\n",
    "\n",
    "# Verificamos si el directorio de descarga existe, si no, lo creamos\n",
    "if not os.path.exists(download_directory):\n",
    "    os.makedirs(download_directory)\n",
    "    print(f\"\\nDirectorio '{download_directory}' creado.\")\n",
    "\n",
    "print(\"\\n--- Iniciando descarga de audios ---\")\n",
    "# Definimos un diccionario para almacenar las rutas de los archivos de audio descargados\n",
    "downloaded_audio_paths = {}\n",
    "\n",
    "# Iteramos sobre la lista de nombres de archivos de audio y los descargamos\n",
    "for audio_file_name in list_of_audio_file_names:\n",
    "    audio_url = f\"{path_to_audio_file}/{audio_file_name}\"\n",
    "    local_file_path = os.path.join(download_directory, audio_file_name)\n",
    "\n",
    "    # Verificamos si el archivo ya existe para evitar descargas duplicadas\n",
    "    try:\n",
    "        print(f\"Descargando: {audio_url} a {local_file_path}\")\n",
    "        response = requests.get(audio_url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(local_file_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"Descarga completada: {audio_file_name}\")\n",
    "        downloaded_audio_paths[audio_file_name] = local_file_path\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error al descargar {audio_file_name}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado durante la descarga de {audio_file_name}: {e}\")\n",
    "\n",
    "print(\"\\n--- Proceso de descarga de audios finalizado. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6uYgtCvvJSmq"
   },
   "source": [
    "# **Ejercicio 2a:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAQjVP2HkoZY"
   },
   "source": [
    "* #### **Comenten el por qué del modelo seleccionado para extracción del texto de los audios.**\n",
    "\n",
    "* #### **Extraer el contenido de los audios en texto.**\n",
    "\n",
    "* #### **Sugerencia:** pueden extraerlo en un formato de diccionario, clave:valor $→$ {audio01:fabula01, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "IjKIqrqczmC4"
   },
   "outputs": [],
   "source": [
    "# Definimos una función para transcribir el audio a texto utilizando la API de OpenAI\n",
    "def audio2file(audio_path_full):\n",
    "  \"Transcribe un archivo de audio a texto utilizando el modelo Whisper-1 de OpenAI.\"\n",
    "  try:\n",
    "    print(f\"Transcribiendo audio: {os.path.basename(audio_path_full)}\")\n",
    "    with open(audio_path_full, \"rb\") as audio_file:\n",
    "\n",
    "      transcript = client.audio.transcriptions.create(model=\"whisper-1\", # Usamos el modelo Whisper-1 de OpenAI\n",
    "                                                      file=audio_file, # Archivo de audio a transcribir\n",
    "                                                      language=\"es\" # Especificamos el idioma del audio como español\n",
    "                                                      )\n",
    "    print(f\"Transcripción exitosa para {os.path.basename(audio_path_full)}\")\n",
    "    return transcript.text\n",
    "  except Exception as e:\n",
    "    print(f\"Error al transcribir {os.path.basename(audio_path_full)}: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "C3k5sLGhnO1d",
    "outputId": "01e93c43-ff58-4554-90e1-27a3e31d703a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando transcripción y guardado de resultados ---\n",
      "Transcribiendo audio: 21144-01.mp3\n",
      "Transcripción exitosa para 21144-01.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-01.pkl\n",
      "Transcribiendo audio: 21144-04.mp3\n",
      "Transcripción exitosa para 21144-04.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-04.pkl\n",
      "Transcribiendo audio: 21144-05.mp3\n",
      "Transcripción exitosa para 21144-05.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-05.pkl\n",
      "Transcribiendo audio: 21144-06.mp3\n",
      "Transcripción exitosa para 21144-06.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-06.pkl\n",
      "Transcribiendo audio: 21144-14.mp3\n",
      "Transcripción exitosa para 21144-14.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-14.pkl\n",
      "Transcribiendo audio: 21144-22.mp3\n",
      "Transcripción exitosa para 21144-22.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-22.pkl\n",
      "Transcribiendo audio: 21144-24.mp3\n",
      "Transcripción exitosa para 21144-24.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-24.pkl\n",
      "Transcribiendo audio: 21144-25.mp3\n",
      "Transcripción exitosa para 21144-25.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-25.pkl\n",
      "Transcribiendo audio: 21144-26.mp3\n",
      "Transcripción exitosa para 21144-26.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-26.pkl\n",
      "Transcribiendo audio: 21144-27.mp3\n",
      "Transcripción exitosa para 21144-27.mp3\n",
      "Transcripción guardada en: transcripciones_pkl\\21144-27.pkl\n",
      "\n",
      "--- Proceso de transcripción y guardado finalizado. ---\n"
     ]
    }
   ],
   "source": [
    "# Definimos el directorio donde se guardarán las transcripciones en formato .pkl\n",
    "transcripts_directory = \"transcripciones_pkl\"\n",
    "\n",
    "# Verificamos si el directorio de transcripciones existe, si no, lo creamos\n",
    "if not os.path.exists(transcripts_directory):\n",
    "    os.makedirs(transcripts_directory)\n",
    "    print(f\"\\nDirectorio '{transcripts_directory}' creado.\")\n",
    "\n",
    "print(\"\\n--- Iniciando transcripción y guardado de resultados ---\")\n",
    "# Iteramos sobre los archivos de audio\n",
    "for audio_path_full in downloaded_audio_paths:\n",
    "    # Obtenemos la ruta completa del archivo de audio\n",
    "    transcribed_text = audio2file(f\"{download_directory}/{audio_path_full}\")\n",
    "\n",
    "    # Si la transcripción fue exitosa, guardamos el texto en un archivo .pkl\n",
    "    if transcribed_text:\n",
    "        # Obtenemos el nombre base del archivo de audio sin la extensión\n",
    "        base_name = os.path.splitext(os.path.basename(audio_path_full))[0]\n",
    "        # Definimos el nombre del archivo .pkl para guardar la transcripción\n",
    "        pkl_file_name = f\"{base_name}.pkl\"\n",
    "        pkl_full_path = os.path.join(transcripts_directory, pkl_file_name)\n",
    "        # Verificamos si el archivo .pkl ya existe y lo renombramos si es necesario\n",
    "        try:\n",
    "            # Guardamos la transcripción en un archivo .pkl\n",
    "            with open(pkl_full_path, 'wb') as f:\n",
    "                pickle.dump(transcribed_text, f)\n",
    "            print(f\"Transcripción guardada en: {pkl_full_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al guardar el archivo PKL para {pkl_file_name}: {e}\")\n",
    "    else:\n",
    "        print(f\"No se pudo transcribir {os.path.basename(audio_path_full)}, por lo tanto no se guardará un archivo PKL.\")\n",
    "\n",
    "print(\"\\n--- Proceso de transcripción y guardado finalizado. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qJTsHAVrzmC5"
   },
   "source": [
    "## Comentario por que seccionamos el modelo whisper-1\n",
    "\n",
    "El modelo Whisper-1 es un modelo de transcripción de audio a texto desarrollado por OpenAI.\n",
    "\n",
    "Es conocido por su capacidad para manejar múltiples idiomas y dialectos, así como por su precisión en la transcripción de audio.\n",
    "\n",
    "Este modelo es especialmente útil para transcribir audios en español, ya que ha sido entrenado con una amplia variedad de datos en diferentes idiomas.\n",
    "\n",
    "A diferencia de otros modelos mas robustos, Whisper-1 es ligero y rápido, lo que lo hace adecuado para actividades académicas y proyectos de investigación como el nuestro.\n",
    "\n",
    "Cabe mencionar que Whisper-1 es un modelo de código abierto, lo que permite su uso y adaptación en una amplia gama de aplicaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NM0D83j8EWiN"
   },
   "source": [
    "# **Ejercicio 2b:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xiFG5q88EYHU"
   },
   "source": [
    "* #### **Eliminar el inicio y final comunes de los textos extraídos de cada fábula.**\n",
    "\n",
    "* #### **Sugerencia:** Pueden guardar esta información en un archivo tipo JSON, para que al estar probando diferentes opciones en los ejercicios siguientes, puedan recuperar rápidamente la información de cada video/fábula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "error",
     "timestamp": 1749408555512,
     "user": {
      "displayName": "Jesús Antonio López Wayas",
      "userId": "16819167153657833693"
     },
     "user_tz": 360
    },
    "id": "KkbeTmeon_RP",
    "outputId": "3f33086a-cace-4504-cae5-712f07cdf406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Cargando transcripciones desde archivos PKL ---\n",
      "Cargado 21144-01.pkl como audio01\n",
      "Cargado 21144-04.pkl como audio04\n",
      "Cargado 21144-05.pkl como audio05\n",
      "Cargado 21144-06.pkl como audio06\n",
      "Cargado 21144-14.pkl como audio14\n",
      "Cargado 21144-22.pkl como audio22\n",
      "Cargado 21144-24.pkl como audio24\n",
      "Cargado 21144-25.pkl como audio25\n",
      "Cargado 21144-26.pkl como audio26\n",
      "Cargado 21144-27.pkl como audio27\n",
      "\n",
      "--- Transcripciones unificadas guardadas en: transcripciones_unificadas.json ---\n"
     ]
    }
   ],
   "source": [
    "# Definimos un diccionario para almacenar las transcripciones unificadas\n",
    "transcriptions_dict = {}\n",
    "\n",
    "print(\"\\n--- Cargando transcripciones desde archivos PKL ---\")\n",
    "# Iteramos sobre los archivos .pkl en el directorio de transcripciones\n",
    "for filename in os.listdir(transcripts_directory):\n",
    "    # Verificamos si el archivo es un archivo .pkl\n",
    "    if filename.endswith(\".pkl\"):\n",
    "        pkl_full_path = os.path.join(transcripts_directory, filename)\n",
    "        # Intentamos cargar el archivo .pkl\n",
    "        try:\n",
    "            with open(pkl_full_path, 'rb') as f:\n",
    "                transcribed_text = pickle.load(f)\n",
    "            # Extraemos el número de audio del nombre del archivo usando una expresión regular\n",
    "            audio_number = re.search(r'(\\d{2})\\.pkl$', filename).group(1)\n",
    "            # Creamos una clave para el diccionario de transcripciones\n",
    "            key = f\"audio{audio_number}\"\n",
    "            # Añadimos la transcripción al diccionario\n",
    "            transcriptions_dict[key] = transcribed_text\n",
    "            print(f\"Cargado {filename} como {key}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al cargar {filename}: {e}\")\n",
    "\n",
    "# Definimos la ruta para guardar el archivo JSON unificado\n",
    "unified_json_path = \"transcripciones_unificadas.json\"\n",
    "# Intentamos guardar el diccionario de transcripciones en un archivo JSON\n",
    "try:\n",
    "    with open(unified_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(transcriptions_dict, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"\\n--- Transcripciones unificadas guardadas en: {unified_json_path} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo JSON unificado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5eWgjuHYzmC5",
    "outputId": "862d7f7f-963b-4f5b-8574-60acc7b2dc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Procesando transcripciones para eliminar inicios y finales comunes (flexible) ---\n",
      "'audio01': Eliminado inicio y final comunes.\n",
      "'audio04': Eliminado inicio y final comunes.\n",
      "'audio05': Eliminado inicio y final comunes.\n",
      "'audio06': Eliminado inicio y final comunes.\n",
      "'audio14': Eliminado inicio y final comunes.\n",
      "'audio22': Eliminado inicio y final comunes.\n",
      "'audio24': Eliminado inicio y final comunes.\n",
      "'audio25': Eliminado inicio y final comunes.\n",
      "'audio26': Eliminado inicio y final comunes.\n",
      "'audio27': Eliminado inicio y final comunes.\n",
      "\n",
      "--- Transcripciones procesadas guardadas en: transcripciones_procesadas.json ---\n"
     ]
    }
   ],
   "source": [
    "# Ahora procesamos el archivo JSON unificado para eliminar inicios y finales comunes\n",
    "try:\n",
    "    with open(unified_json_path, 'r', encoding='utf-8') as f:\n",
    "        unified_transcriptions = json.load(f)\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el archivo JSON para procesamiento: {e}\")\n",
    "    unified_transcriptions = {}\n",
    "# Definimos un diccionario para almacenar las transcripciones procesadas\n",
    "processed_transcriptions = {}\n",
    "\n",
    "# Definimos patrones de inicio y final comunes para eliminar\n",
    "common_start_pattern = r\".+\\d+.\"\n",
    "common_end_pattern = \"Fin de .+\"\n",
    "\n",
    "print(\"\\n--- Procesando transcripciones para eliminar inicios y finales comunes (flexible) ---\")\n",
    "# Iteramos sobre las transcripciones unificadas y aplicamos los patrones de limpieza\n",
    "for key, text in unified_transcriptions.items():\n",
    "    # Limpiamos el texto eliminando los inicios y finales comunes\n",
    "    cleaned_text = text\n",
    "    cleaned_text = re.sub(common_start_pattern, \"\", cleaned_text, 1, re.IGNORECASE | re.DOTALL).strip()\n",
    "    match_end = re.search(common_end_pattern, cleaned_text, re.IGNORECASE | re.DOTALL)\n",
    "    # Si encontramos un patrón de final común, lo eliminamos\n",
    "    if match_end:\n",
    "        cleaned_text = cleaned_text[:match_end.start()].strip()\n",
    "        print(f\"'{key}': Eliminado inicio y final comunes.\")\n",
    "    else:\n",
    "        print(f\"'{key}': Solo eliminado inicio común (o patrón final no encontrado).\")\n",
    "    # Añadimos la transcripción procesada al diccionario\n",
    "    processed_transcriptions[key] = cleaned_text\n",
    "\n",
    "# Definimos la ruta para guardar el archivo JSON de transcripciones procesadas\n",
    "processed_json_path = \"transcripciones_procesadas.json\"\n",
    "# Intentamos guardar las transcripciones procesadas en un archivo JSON\n",
    "try:\n",
    "    with open(processed_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(processed_transcriptions, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"\\n--- Transcripciones procesadas guardadas en: {processed_json_path} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo JSON de transcripciones procesadas: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0zC3FoNizmC5",
    "outputId": "d4977e5b-fbea-4df6-ec3d-03f551b95f91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio01': 'El lobo y el cordero en el templo Dándose cuenta de que era perseguido por un lobo, un pequeño corderito decidió refugiarse en un templo cercano. Lo llamó lobo y le dijo que si el sacrificador lo encontraba allí adentro, lo inmolaría a su dios. Mejor así, replicó el cordero, prefiero ser víctima para un dios a tener que perecer en tus colmillos. Si sin remedio vamos a ser sacrificados, más nos vale que sea con el mayor honor.',\n",
       " 'audio04': 'El Lobo y la Cruz. A un lobo que comía un hueso, se le atragantó el hueso en la garganta y corría por todas partes en busca de auxilio. Encontró en su correra a una grulla y le pidió que le salvara de aquella situación y que enseguida le pagaría por ello. Aceptó la grulla e introdujo su cabeza en la boca del lobo, sacando de la garganta el hueso atravesado. Pidió entonces la cancelación de la paga convenida. Oye, amiga, dijo el lobo, ¿no crees que es suficiente paga con haber sacado tu cabeza sana y salva de mi boca? Nunca hagas favores a malvados, traficantes o corruptos, pues mucha paga tendrías si te dejan sano y salvo.',\n",
       " 'audio05': 'El lobo y el caballo. Pasaba un lobo por un sembrado de cebada, pero como no era comida de su gusto, la dejó y siguió su camino. Encontró al rato a un caballo y le llevó al campo comentándole la gran cantidad de cebada que había hallado, pero que en vez de comérsela a él, mejor se la había dejado porque le agradaba más oír el ruido de sus dientes al masticarla. Pero el caballo le repuso. Amigo, si los lobos comieran cebada, no hubieras preferido complacer a tus oídos sino a tu estómago. A todo malvado, aunque parezca actuar como bueno, no debe de creérsele.',\n",
       " 'audio06': 'El Lobo y el Asno. Un lobo fue elegido rey entre sus congéneres y decretó una ley ordenando que lo que cada uno capturase en la casa, lo pusiera en común y lo repartiese por partes iguales entre todos. De esta manera ya no tendrían los lobos que devorarse unos a otros en épocas de hambre. Pero en eso le escuchó un asno, que estaba por ahí cerca, y moviendo sus orejas le dijo ¡Magnífica idea ha brotado de tu corazón! Pero, ¿por qué has escondido todo tu botín en tu cueva? Llévalo a la comunidad y repártelo también como lo has decretado. El lobo, descubierto y confundido, derogó su ley. Si alguna vez llegas a tener poder de legislar, sé el primero en cumplir tus propias leyes.',\n",
       " 'audio14': 'El Lobo y el Cabrito Encerrado. Protegido por la seguridad del corral de una casa, un cabrito vio pasar a un lobo y comenzó a insultarle burlándose ampliamente de él. El lobo serenamente le replicó. ¡Infeliz! Sé que no eres tú quien me está insultando, sino el sitio en que te encuentras. Muy a menudo no es el valor, sino la ocasión y el lugar quienes proveen el enfrentamiento arrogante ante los poderosos.',\n",
       " 'audio22': 'El perro y la almeja. Un perro de esos, acostumbrados a comer huevos, al ver una almeja, no lo pensó dos veces, y creyendo que se trataba de un huevo, se la tragó inmediatamente. Desgarradas luego sus entrañas, se sintió muy mal, y se dijo, bien merecido lo tengo, por creer que todo lo que veo redondo son huevos. Nunca tomes un asunto sin antes reflexionar, para no entrar luego en extrañas dificultades.',\n",
       " 'audio24': 'El perro y el reflejo en el río. Badeaba un perro un río, llevando en su hocico un sabroso pedazo de carne. Vio su propio reflejo en el agua del río y creyó que aquel reflejo era, en realidad, otro perro que llevaba un trozo de carne mayor que el suyo. Y deseando adueñarse del pedazo ajeno, soltó el suyo para arrebatar el trozo a su supuesto compadre. Pero el resultado fue que se quedó sin el propio y sin el ajeno. Este porque no existía, solo era un reflejo, y el otro, el verdadero, porque se lo llevó a la corriente. Nunca codices el bien ajeno, pues puedes perder lo que ya has adquirido con tu esfuerzo.',\n",
       " 'audio25': 'El perro y el carnicero Penetró un perro en una carnicería, y notando que el carnicero estaba muy ocupado con sus clientes, cogió un trozo de carne y salió corriendo. Se volvió el carnicero, y viéndole huir, y sin poder hacer ni nada, exclamó, —¡Oye, amigo! Ahí donde te encuentre, no dejaré de mirarte. No esperes a que suceda un accidente para pensar en cómo evitarlo.',\n",
       " 'audio26': 'El perro con campanilla. Había un perro que acostumbraba a morder sin razón. Le puso su amo una campanilla para advertirle a la gente de su presencia cercana. Y el can, sonando la campanilla, se fue a la plaza pública a presumir. Mas una sabia perra, ya avanzada de años, le dijo. ¿De qué presumes tanto, amigo? Sé que no llevas esa campanilla por tus grandes virtudes, sino para anunciar tu maldad oculta. Los halagos que se hacen a sí mismo, los fanfarrones, sólo delatan sus mayores defectos.',\n",
       " 'audio27': 'El perro que perseguía al león. Un perro de casa se encontró con un león y partió en su persecución. Pero el león se volvió rugiendo y el perro, todo temorizado, retrocedió rápidamente por el mismo camino. Le vio una zorra y le dijo, ¡Perro infeliz! Primero perseguías al león y ya ni siquiera soportas sus surgidos. Cuando entres a una empresa, mantente siempre listo a afrontar imprevistos que no te imaginabas.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las transcripciones procesadas\n",
    "processed_transcriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PKaB_Ge0Shc"
   },
   "source": [
    "# **Ejercicio 3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNrqcQFe0VWR"
   },
   "source": [
    "* #### **Apliquen el proceso de limpieza que consideren adecuado.**\n",
    "\n",
    "* #### **Justifiquen los pasos de limpieza utilizados. Tomen en cuenta que el texto extraído de cada fábula es relativamente pequeño.**\n",
    "\n",
    "* #### **En caso de que decidan no aplicar esta etapa de limpieza, deberán justificarlo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pqwiCCdpq8D_",
    "outputId": "23a62703-fb23-4105-dc3f-63ff817d67de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando proceso de limpieza de texto ---\n",
      "Limpieza completada para 'audio01'.\n",
      "Limpieza completada para 'audio04'.\n",
      "Limpieza completada para 'audio05'.\n",
      "Limpieza completada para 'audio06'.\n",
      "Limpieza completada para 'audio14'.\n",
      "Limpieza completada para 'audio22'.\n",
      "Limpieza completada para 'audio24'.\n",
      "Limpieza completada para 'audio25'.\n",
      "Limpieza completada para 'audio26'.\n",
      "Limpieza completada para 'audio27'.\n",
      "\n",
      "--- Transcripciones limpias guardadas en: transcripciones_limpias.json ---\n",
      "\n",
      "¡Proceso de limpieza de texto finalizado!\n"
     ]
    }
   ],
   "source": [
    "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
    "# Definimos la ruta para guardar el archivo JSON de transcripciones limpias\n",
    "cleaned_json_path = \"transcripciones_limpias.json\"\n",
    "# Definimos un diccionario para almacenar las transcripciones limpias\n",
    "cleaned_transcriptions = {}\n",
    "\n",
    "print(\"\\n--- Iniciando proceso de limpieza de texto ---\")\n",
    "# Iteramos sobre las transcripciones procesadas y limpiamos el texto\n",
    "for key, text in processed_transcriptions.items():\n",
    "    # Convertimos el texto a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminamos caracteres especiales y puntuación\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    # Eliminamos números\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    # Eliminamos múltiples espacios en blanco\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    # Eliminamos las stopwords en español\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words_es and len(word) > 1]\n",
    "    text = ' '.join(filtered_words)\n",
    "    # Añadimos la transcripción limpia al diccionario definido\n",
    "    cleaned_transcriptions[key] = text\n",
    "    print(f\"Limpieza completada para '{key}'.\")\n",
    "# Intentamos guardar las transcripciones limpias en un archivo JSON\n",
    "try:\n",
    "    with open(cleaned_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(cleaned_transcriptions, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"\\n--- Transcripciones limpias guardadas en: {cleaned_json_path} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo JSON de transcripciones limpias: {e}\")\n",
    "\n",
    "print(\"\\n¡Proceso de limpieza de texto finalizado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BtPUwfyJzmC6",
    "outputId": "67b3774c-89de-4a85-cb3f-3b973d5c14d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio01': 'lobo cordero templo dándose cuenta perseguido lobo pequeño corderito decidió refugiarse templo cercano llamó lobo dijo si sacrificador encontraba allí adentro inmolaría dios mejor así replicó cordero prefiero ser víctima dios tener perecer colmillos si remedio vamos ser sacrificados vale mayor honor',\n",
       " 'audio04': 'lobo cruz lobo comía hueso atragantó hueso garganta corría todas partes busca auxilio encontró correra grulla pidió salvara aquella situación enseguida pagaría ello aceptó grulla introdujo cabeza boca lobo sacando garganta hueso atravesado pidió entonces cancelación paga convenida oye amiga dijo lobo crees suficiente paga haber sacado cabeza sana salva boca nunca hagas favores malvados traficantes corruptos pues mucha paga si dejan sano salvo',\n",
       " 'audio05': 'lobo caballo pasaba lobo sembrado cebada comida gusto dejó siguió camino encontró rato caballo llevó campo comentándole gran cantidad cebada hallado vez comérsela mejor dejado agradaba oír ruido dientes masticarla caballo repuso amigo si lobos comieran cebada preferido complacer oídos sino estómago malvado aunque parezca actuar bueno debe creérsele',\n",
       " 'audio06': 'lobo asno lobo elegido rey congéneres decretó ley ordenando cada capturase casa pusiera común repartiese partes iguales manera lobos devorarse épocas hambre escuchó asno ahí cerca moviendo orejas dijo magnífica idea brotado corazón escondido botín cueva llévalo comunidad repártelo decretado lobo descubierto confundido derogó ley si alguna vez llegas tener poder legislar sé primero cumplir propias leyes',\n",
       " 'audio14': 'lobo cabrito encerrado protegido seguridad corral casa cabrito vio pasar lobo comenzó insultarle burlándose ampliamente lobo serenamente replicó infeliz sé insultando sino sitio encuentras menudo valor sino ocasión lugar proveen enfrentamiento arrogante poderosos',\n",
       " 'audio22': 'perro almeja perro acostumbrados comer huevos ver almeja pensó dos veces creyendo trataba huevo tragó inmediatamente desgarradas luego entrañas sintió mal dijo bien merecido creer veo redondo huevos nunca tomes asunto reflexionar entrar luego extrañas dificultades',\n",
       " 'audio24': 'perro reflejo río badeaba perro río llevando hocico sabroso pedazo carne vio propio reflejo agua río creyó aquel reflejo realidad perro llevaba trozo carne mayor deseando adueñarse pedazo ajeno soltó arrebatar trozo supuesto compadre resultado quedó propio ajeno existía solo reflejo verdadero llevó corriente nunca codices bien ajeno pues puedes perder adquirido esfuerzo',\n",
       " 'audio25': 'perro carnicero penetró perro carnicería notando carnicero ocupado clientes cogió trozo carne salió corriendo volvió carnicero viéndole huir poder hacer exclamó oye amigo ahí encuentre dejaré mirarte esperes suceda accidente pensar cómo evitarlo',\n",
       " 'audio26': 'perro campanilla perro acostumbraba morder razón puso amo campanilla advertirle gente presencia cercana can sonando campanilla plaza pública presumir mas sabia perra avanzada años dijo presumes amigo sé llevas campanilla grandes virtudes sino anunciar maldad oculta halagos hacen mismo fanfarrones sólo delatan mayores defectos',\n",
       " 'audio27': 'perro perseguía león perro casa encontró león partió persecución león volvió rugiendo perro temorizado retrocedió rápidamente mismo camino vio zorra dijo perro infeliz primero perseguías león siquiera soportas surgidos entres empresa mantente siempre listo afrontar imprevistos imaginabas'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos las transcripciones limpias\n",
    "cleaned_transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "iHYMfJJv4yKn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud de la Fábula original: 429\n",
      "Longitud de la Fábula después de limpieza: 300\n"
     ]
    }
   ],
   "source": [
    "# Mostramos la longitud de la primera fábula antes y después de ser tratada\n",
    "\n",
    "# Convertimos a list todos las fábulas para medir el nivel de coherencia de neustro entrenamiento más adelante\n",
    "cleaned_transcriptions_list = list(cleaned_transcriptions.values())\n",
    "\n",
    "print(f'Longitud de la Fábula original: {len(list(processed_transcriptions.values())[0])}')\n",
    "print(f'Longitud de la Fábula después de limpieza: {len(cleaned_transcriptions_list[0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKmVlOUfzmC6"
   },
   "source": [
    "### **Justificación de los pasos de limpieza utilizados.**\n",
    "\n",
    "Es necesario limpiar los textos extraídos de los audios para mejorar la calidad del análisis posterior. Los pasos realizados fueron los siguientes:\n",
    "1. Convertimos el texto a minusculas para despreocuparnos de mayusculas y minusculas.\n",
    "2. Eliminamos números y signos de puntuación para enfocarnos en las palabras relevantes.\n",
    "2. Eliminamos espacios en blanco y extras para evitar problemas de tokenización.\n",
    "3. Tokenizamos el texto y eliminamos las stopwords (en español) para centrarnos en las palabras clave que aportan significado.\n",
    "4. Conservamos tokens mayores a 1 carácter para evitar palabras irrelevantes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2ywrmsMP_EF"
   },
   "source": [
    "# **Ejercicio 4:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "-xFpnt0A0Ub7"
   },
   "outputs": [],
   "source": [
    "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
    "\n",
    "# Definimos una función para extraer palabras clave usando LDA (Latent Dirichlet Allocation)\n",
    "def extract_lda_keywords(text_content, num_keywords=20):\n",
    "    \"\"\"\n",
    "    Extrae palabras clave de un texto usando LDA, asumiendo un solo tópico.\n",
    "    \"\"\"\n",
    "    # Verificamos si el texto está vacío o solo contiene espacios\n",
    "    if not text_content.strip():\n",
    "        return None\n",
    "\n",
    "    tokens = text_content.split() # Tokenizamos el texto en palabras\n",
    "    id2word = corpora.Dictionary([tokens]) # Creamos un diccionario de Gensim a partir de los tokens\n",
    "    corpus = [id2word.doc2bow(tokens)] # Creamos el corpus de Gensim a partir de los tokens\n",
    "\n",
    "    # Verificamos si el corpus y el diccionario son válidos\n",
    "    if not corpus or not id2word:\n",
    "        return None\n",
    "\n",
    "    # Intentamos crear el modelo LDA y extraer las palabras clave\n",
    "    try:\n",
    "        lda_model = gensim.models.ldamodel.LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=id2word,\n",
    "            num_topics=1,      # Sirve para extraer uno o varios tópicos, en este caso solo uno\n",
    "            chunksize=1,       # Procesamos un documento a la vez\n",
    "            passes=25,         # Número de pasadas para el entrenamiento\n",
    "            alpha='auto',      # 'auto' puede funcionar mejor que valores fijos\n",
    "            eta='auto',        # 'auto' puede funcionar mejor que valores fijos\n",
    "            random_state=100   # Para reproducibilidad\n",
    "        )\n",
    "        # Extraemos las palabras clave del modelo LDA\n",
    "        keywords = lda_model.print_topics(num_topics=1, num_words=num_keywords)\n",
    "\n",
    "        # Convertimos cleaned_transcriptions_list a lista de listas de tokens\n",
    "        texts_tokenized = [doc.split() for doc in cleaned_transcriptions_list]\n",
    "\n",
    "        # Evaluar coherencia\n",
    "        coherence_model_lda = CoherenceModel(\n",
    "            model=lda_model,\n",
    "            texts=texts_tokenized,\n",
    "            dictionary=id2word,\n",
    "            coherence='c_v',\n",
    "            window_size=2,\n",
    "            topn=10,\n",
    "        )\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "        # Retornamos las palabras clave del primer tópico\n",
    "        if keywords:\n",
    "            return keywords[0][1], coherence_lda\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante el modelado LDA para el texto: {e}\")\n",
    "        return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "BxMp1SphzmC6",
    "outputId": "15d42a72-f49d-4acb-d57d-3eaf158e8cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extrayendo palabras clave con LDA (Top 20 palabras) ---\n",
      "Palabras clave para audio01:\n",
      "0.052*\"lobo\" + 0.039*\"templo\" + 0.039*\"cordero\" + 0.039*\"si\" + 0.039*\"ser\" + 0.039*\"dios\" + 0.026*\"perecer\" + 0.026*\"perseguido\" + 0.026*\"prefiero\" + 0.026*\"refugiarse\" + 0.026*\"remedio\" + 0.026*\"replicó\" + 0.026*\"sacrificados\" + 0.026*\"adentro\" + 0.026*\"tener\" + 0.026*\"vale\" + 0.026*\"vamos\" + 0.026*\"mayor\" + 0.026*\"sacrificador\" + 0.026*\"pequeño\"\n",
      "\n",
      "Coherencia LDA:  0.5075637440127003\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio04:\n",
      "0.043*\"lobo\" + 0.034*\"hueso\" + 0.034*\"paga\" + 0.026*\"pidió\" + 0.026*\"garganta\" + 0.026*\"boca\" + 0.026*\"cabeza\" + 0.026*\"grulla\" + 0.017*\"todas\" + 0.017*\"suficiente\" + 0.017*\"pues\" + 0.017*\"sacando\" + 0.017*\"oye\" + 0.017*\"pagaría\" + 0.017*\"si\" + 0.017*\"nunca\" + 0.017*\"mucha\" + 0.017*\"malvados\" + 0.017*\"partes\" + 0.017*\"sano\"\n",
      "\n",
      "Coherencia LDA:  0.5939447046776785\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio05:\n",
      "0.043*\"cebada\" + 0.043*\"caballo\" + 0.032*\"lobo\" + 0.022*\"preferido\" + 0.022*\"siguió\" + 0.022*\"sino\" + 0.022*\"sembrado\" + 0.022*\"si\" + 0.022*\"pasaba\" + 0.022*\"hallado\" + 0.022*\"parezca\" + 0.022*\"ruido\" + 0.022*\"oídos\" + 0.022*\"mejor\" + 0.022*\"masticarla\" + 0.022*\"malvado\" + 0.022*\"lobos\" + 0.022*\"rato\" + 0.022*\"oír\" + 0.022*\"estómago\"\n",
      "\n",
      "Coherencia LDA:  0.6285079017856667\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio06:\n",
      "0.036*\"lobo\" + 0.027*\"ley\" + 0.027*\"asno\" + 0.018*\"partes\" + 0.018*\"tener\" + 0.018*\"vez\" + 0.018*\"repártelo\" + 0.018*\"si\" + 0.018*\"legislar\" + 0.018*\"orejas\" + 0.018*\"ordenando\" + 0.018*\"manera\" + 0.018*\"sé\" + 0.018*\"magnífica\" + 0.018*\"lobos\" + 0.018*\"llévalo\" + 0.018*\"llegas\" + 0.018*\"leyes\" + 0.018*\"moviendo\" + 0.018*\"poder\"\n",
      "\n",
      "Coherencia LDA:  0.6320707807831892\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio14:\n",
      "0.065*\"lobo\" + 0.048*\"cabrito\" + 0.048*\"sino\" + 0.032*\"ocasión\" + 0.032*\"burlándose\" + 0.032*\"comenzó\" + 0.032*\"ampliamente\" + 0.032*\"pasar\" + 0.032*\"poderosos\" + 0.032*\"protegido\" + 0.032*\"replicó\" + 0.032*\"encerrado\" + 0.032*\"seguridad\" + 0.032*\"serenamente\" + 0.032*\"sitio\" + 0.032*\"sé\" + 0.032*\"valor\" + 0.032*\"lugar\" + 0.032*\"proveen\" + 0.032*\"casa\"\n",
      "\n",
      "Coherencia LDA:  0.5534580949233934\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio22:\n",
      "0.044*\"luego\" + 0.044*\"huevos\" + 0.044*\"almeja\" + 0.044*\"perro\" + 0.029*\"comer\" + 0.029*\"acostumbrados\" + 0.029*\"mal\" + 0.029*\"merecido\" + 0.029*\"nunca\" + 0.029*\"pensó\" + 0.029*\"redondo\" + 0.029*\"reflexionar\" + 0.029*\"sintió\" + 0.029*\"tomes\" + 0.029*\"tragó\" + 0.029*\"trataba\" + 0.029*\"veces\" + 0.029*\"veo\" + 0.029*\"bien\" + 0.029*\"creer\"\n",
      "\n",
      "Coherencia LDA:  0.5778891919555291\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio24:\n",
      "0.054*\"reflejo\" + 0.043*\"ajeno\" + 0.043*\"perro\" + 0.043*\"río\" + 0.032*\"pedazo\" + 0.032*\"propio\" + 0.032*\"trozo\" + 0.032*\"carne\" + 0.022*\"puedes\" + 0.022*\"pues\" + 0.022*\"quedó\" + 0.022*\"realidad\" + 0.022*\"sabroso\" + 0.022*\"solo\" + 0.022*\"soltó\" + 0.022*\"supuesto\" + 0.022*\"verdadero\" + 0.022*\"llevó\" + 0.022*\"resultado\" + 0.022*\"perder\"\n",
      "\n",
      "Coherencia LDA:  0.47201426662897994\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio25:\n",
      "0.063*\"carnicero\" + 0.048*\"perro\" + 0.032*\"huir\" + 0.032*\"amigo\" + 0.032*\"carnicería\" + 0.032*\"accidente\" + 0.032*\"mirarte\" + 0.032*\"notando\" + 0.032*\"ocupado\" + 0.032*\"oye\" + 0.032*\"pensar\" + 0.032*\"cogió\" + 0.032*\"poder\" + 0.032*\"salió\" + 0.032*\"suceda\" + 0.032*\"trozo\" + 0.032*\"viéndole\" + 0.032*\"exclamó\" + 0.032*\"penetró\" + 0.032*\"carne\"\n",
      "\n",
      "Coherencia LDA:  0.4833641651544075\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio26:\n",
      "0.060*\"campanilla\" + 0.036*\"perro\" + 0.024*\"mayores\" + 0.024*\"oculta\" + 0.024*\"perra\" + 0.024*\"plaza\" + 0.024*\"presencia\" + 0.024*\"presumes\" + 0.024*\"presumir\" + 0.024*\"puso\" + 0.024*\"pública\" + 0.024*\"razón\" + 0.024*\"sabia\" + 0.024*\"sino\" + 0.024*\"sonando\" + 0.024*\"sé\" + 0.024*\"sólo\" + 0.024*\"maldad\" + 0.024*\"morder\" + 0.024*\"mismo\"\n",
      "\n",
      "Coherencia LDA:  0.5710288590188606\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Palabras clave para audio27:\n",
      "0.074*\"perro\" + 0.074*\"león\" + 0.029*\"perseguía\" + 0.029*\"empresa\" + 0.029*\"persecución\" + 0.029*\"afrontar\" + 0.029*\"perseguías\" + 0.029*\"primero\" + 0.029*\"retrocedió\" + 0.029*\"rugiendo\" + 0.029*\"rápidamente\" + 0.029*\"siempre\" + 0.029*\"siquiera\" + 0.029*\"soportas\" + 0.029*\"surgidos\" + 0.029*\"temorizado\" + 0.029*\"vio\" + 0.029*\"volvió\" + 0.029*\"casa\" + 0.029*\"entres\"\n",
      "\n",
      "Coherencia LDA:  0.47793233973679916\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "--- Palabras clave guardadas en: fable_keywords_lda.json ---\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Definimos un diccionario para almacenar las palabras clave extraídas de cada fábula\n",
    "fable_keywords = {}\n",
    "# Definimos el número de palabras clave a extraer por fábula\n",
    "num_keywords_per_fable = 20\n",
    "\n",
    "print(f\"\\n--- Extrayendo palabras clave con LDA (Top {num_keywords_per_fable} palabras) ---\")\n",
    "# Iteramos sobre las transcripciones limpias y extraemos las palabras clave\n",
    "for fable_id, fable_text in cleaned_transcriptions.items():\n",
    "    # Extraemos las palabras clave usando la función definida\n",
    "    keywords, coherence_lda = extract_lda_keywords(fable_text, num_keywords_per_fable)\n",
    "    # Si se pudieron extraer palabras clave, las guardamos en el diccionario\n",
    "    if keywords:\n",
    "        fable_keywords[fable_id] = keywords\n",
    "        print(f\"Palabras clave para {fable_id}:\\n{keywords}\\n\")\n",
    "        print('Coherencia LDA: ', coherence_lda)\n",
    "        print('-' * 100)\n",
    "    else:\n",
    "        fable_keywords[fable_id] = \"No se pudieron extraer palabras clave o texto insuficiente.\"\n",
    "        print(f\"Advertencia: No se pudieron extraer palabras clave para {fable_id} (texto posiblemente vacío o insuficiente).\\n\")\n",
    "\n",
    "# Definimos la ruta para guardar el archivo JSON de palabras clave\n",
    "keywords_json_path = \"fable_keywords_lda.json\"\n",
    "try:\n",
    "    with open(keywords_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(fable_keywords, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"\\n--- Palabras clave guardadas en: {keywords_json_path} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo JSON de palabras clave: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Blrrs1sWwkSx"
   },
   "source": [
    "# **Ejercicio 5a y 5b:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gWvzQ-aNwsVk"
   },
   "source": [
    "* #### **5a: Mediante el LLM que hayan seleccionado, generar un único enunciado que describa o resuma cada fábula.**\n",
    "\n",
    "* #### **5b: Mediante el LLM que hayan seleccionado, generar tres posibles enunciados diferentes relacionados con la historia de la fábula.**\n",
    "\n",
    "* #### **Sugerencia:** En realidad los dos incisos a y b se pueden obtener con un solo prompt que solicite la información y el formato correspondiente para cada una de estas partes. Por ejemplo, para cada fábula la salida puede ser un primer enunciado genérico que resume o describe dicha temática; seguido de tres enunciados, cada uno hablando sobre una situación o parte diferente de la fábula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "Q9UkVPxM0Xii",
    "outputId": "5b813e6c-d494-44c6-e549-7f0d4f8accd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Palabras clave cargadas desde: fable_keywords_lda.json ---\n",
      "\n",
      "--- Generando resúmenes y subtemas para cada fábula con LLM ---\n",
      "Generando resumen y subtemas para audio01 usando gpt-4o...\n",
      "Respuesta recibida para audio01.\n",
      "Generando resumen y subtemas para audio04 usando gpt-4o...\n",
      "Respuesta recibida para audio04.\n",
      "Generando resumen y subtemas para audio05 usando gpt-4o...\n",
      "Respuesta recibida para audio05.\n",
      "Generando resumen y subtemas para audio06 usando gpt-4o...\n",
      "Respuesta recibida para audio06.\n",
      "Generando resumen y subtemas para audio14 usando gpt-4o...\n",
      "Respuesta recibida para audio14.\n",
      "Generando resumen y subtemas para audio22 usando gpt-4o...\n",
      "Respuesta recibida para audio22.\n",
      "Generando resumen y subtemas para audio24 usando gpt-4o...\n",
      "Respuesta recibida para audio24.\n",
      "Generando resumen y subtemas para audio25 usando gpt-4o...\n",
      "Respuesta recibida para audio25.\n",
      "Generando resumen y subtemas para audio26 usando gpt-4o...\n",
      "Respuesta recibida para audio26.\n",
      "Generando resumen y subtemas para audio27 usando gpt-4o...\n",
      "Respuesta recibida para audio27.\n",
      "\n",
      "--- Resúmenes y subtemas guardados en: fable_summaries_subtopics.json ---\n",
      "\n",
      "¡Proceso de generación de resúmenes y subtemas completado!\n"
     ]
    }
   ],
   "source": [
    "# Incluyan a continuación todas las celdas (de código o texto) que deseen...\n",
    "\n",
    "# Definimos las rutas de los archivos JSON que contienen las palabras clave y los resúmenes\n",
    "keywords_json_path = \"fable_keywords_lda.json\"\n",
    "summaries_json_path = \"fable_summaries_subtopics.json\"\n",
    "\n",
    "# Verificamos si el archivo de palabras clave existe y lo cargamos\n",
    "try:\n",
    "    with open(keywords_json_path, 'r', encoding='utf-8') as f:\n",
    "        fable_keywords = json.load(f)\n",
    "    print(f\"\\n--- Palabras clave cargadas desde: {keywords_json_path} ---\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: El archivo '{keywords_json_path}' no se encontró. Asegúrate de haber ejecutado la etapa de extracción de palabras clave con LDA.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el archivo JSON de palabras clave: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Definimos una función para generar un resumen y subtemas utilizando un LLM (Large Language Model)\n",
    "def generate_summary_and_subtopics(fable_id, keywords_string, model=\"gpt-4o\"):\n",
    "    \"Genera un resumen y tres subtemas para una fábula utilizando un LLM.\"\n",
    "    # Verificamos si las palabras clave son válidas\n",
    "    if not keywords_string or \"No se pudieron extraer\" in keywords_string:\n",
    "        print(f\"Saltando {fable_id}: No hay palabras clave válidas para procesar.\")\n",
    "        return None\n",
    "\n",
    "    # Limpiamos la cadena de palabras clave para eliminar números y espacios innecesarios\n",
    "    keywords_clean = re.sub(r'\\*\\d+\\.\\d+', '', keywords_string)\n",
    "    # Eliminamos espacios adicionales y convertimos a minúsculas\n",
    "    keywords_list = [kw.strip() for kw in keywords_clean.split('+')]\n",
    "    # Definimos el prompt para el modelo LLM\n",
    "    prompt = f\"\"\"Basado en las siguientes palabras clave para una fábula en español:\n",
    "\"{', '.join(keywords_list)}\"\n",
    "\n",
    "Por favor, realiza las siguientes tareas:\n",
    "1. Genera un único enunciado conciso que resuma o describa el tema central de la fábula.\n",
    "2. Genera tres posibles subtemas (enunciados) diferentes, también concisos, que profundicen o exploren aspectos secundarios de la fábula.\n",
    "\n",
    "Formato de la respuesta:\n",
    "Resumen: [Tu enunciado de resumen]\n",
    "Subtema 1: [Tu primer subtema]\n",
    "Subtema 2: [Tu segundo subtema]\n",
    "Subtema 3: [Tu tercer subtema]\"\"\"\n",
    "\n",
    "    # Definimos los mensajes para la API de OpenAI\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Eres un experto en fábulas y análisis de texto. Tu objetivo es generar resúmenes y subtemas claros y relevantes basados en palabras clave.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Intentamos generar el resumen y los subtemas usando la API de OpenAI\n",
    "    try:\n",
    "        print(f\"Generando resumen y subtemas para {fable_id} usando {model}...\")\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=0.7, # Controla la creatividad (0.0 es determinista, 1.0 es muy creativo)\n",
    "            max_tokens=250   # Límite para evitar respuestas excesivamente largas\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        print(f\"Respuesta recibida para {fable_id}.\")\n",
    "\n",
    "        # Definimos un diccionario para almacenar el resumen y los subtemas\n",
    "        summary_data = {}\n",
    "        lines = content.split('\\n')\n",
    "        # Procesamos la respuesta para extraer el resumen y los subtemas\n",
    "        for line in lines:\n",
    "            if line.startswith(\"Resumen:\"):\n",
    "                summary_data[\"Resumen\"] = line.replace(\"Resumen:\", \"\").strip()\n",
    "            elif line.startswith(\"Subtema 1:\"):\n",
    "                summary_data[\"Subtema 1\"] = line.replace(\"Subtema 1:\", \"\").strip()\n",
    "            elif line.startswith(\"Subtema 2:\"):\n",
    "                summary_data[\"Subtema 2\"] = line.replace(\"Subtema 2:\", \"\").strip()\n",
    "            elif line.startswith(\"Subtema 3:\"):\n",
    "                summary_data[\"Subtema 3\"] = line.replace(\"Subtema 3:\", \"\").strip()\n",
    "\n",
    "        # Verificamos que se hayan extraído todos los campos necesarios\n",
    "        if all(k in summary_data for k in [\"Resumen\", \"Subtema 1\", \"Subtema 2\", \"Subtema 3\"]):\n",
    "            return summary_data\n",
    "        else:\n",
    "            print(f\"Advertencia: No se pudieron parsear todos los campos para {fable_id}. Respuesta cruda:\\n{content}\")\n",
    "            return {\"Resumen\": content, \"Subtema 1\": \"N/A\", \"Subtema 2\": \"N/A\", \"Subtema 3\": \"N/A\"}\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"Error de conexión a la API de OpenAI para {fable_id}: {e}\")\n",
    "        return None\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"Error de límite de tasa (Rate Limit) para {fable_id}: {e}. Espera y reintenta.\")\n",
    "        return None\n",
    "    except openai.APIStatusError as e:\n",
    "        print(f\"Error de estado de la API para {fable_id}: {e.status_code} - {e.response}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error inesperado al llamar a la API de OpenAI para {fable_id}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Definimos un diccionario para almacenar los resúmenes y subtemas de cada fábula\n",
    "fable_summaries_and_subtopics = {}\n",
    "\n",
    "print(\"\\n--- Generando resúmenes y subtemas para cada fábula con LLM ---\")\n",
    "# Iteramos sobre las palabras clave de cada fábula y generamos el resumen y subtemas\n",
    "for fable_id, keywords_string in fable_keywords.items():\n",
    "    result = generate_summary_and_subtopics(fable_id, keywords_string, model=\"gpt-4o\")\n",
    "    if result:\n",
    "        fable_summaries_and_subtopics[fable_id] = result\n",
    "    else:\n",
    "        fable_summaries_and_subtopics[fable_id] = {\n",
    "            \"Resumen\": \"No se pudo generar el resumen.\",\n",
    "            \"Subtema 1\": \"No se pudo generar el subtema 1.\",\n",
    "            \"Subtema 2\": \"No se pudo generar el subtema 2.\",\n",
    "            \"Subtema 3\": \"No se pudo generar el subtema 3.\"\n",
    "        }\n",
    "\n",
    "try:\n",
    "    with open(summaries_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(fable_summaries_and_subtopics, f, ensure_ascii=False, indent=4)\n",
    "    print(f\"\\n--- Resúmenes y subtemas guardados en: {summaries_json_path} ---\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al guardar el archivo JSON de resúmenes y subtemas: {e}\")\n",
    "\n",
    "print(\"\\n¡Proceso de generación de resúmenes y subtemas completado!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "gHBO76tOzmC7",
    "outputId": "c6bbfee1-fbce-4a25-db48-724f0f07f1ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio01': {'Resumen': 'Un cordero, perseguido por un lobo, busca refugio en un templo, prefiriendo enfrentar el sacrificio antes que perecer devorado.',\n",
       "  'Subtema 1': 'La elección del cordero entre dos peligros, resaltando el dilema de buscar un mal menor como alternativa.',\n",
       "  'Subtema 2': 'La paradoja de un lugar sagrado que ofrece una solución temporal pero conlleva su propio riesgo.',\n",
       "  'Subtema 3': 'La crítica a los sacrificios religiosos, cuestionando si el refugio en el templo es realmente una salvación para el cordero.'},\n",
       " 'audio04': {'Resumen': 'Un lobo, al tragarse un hueso, pide ayuda a una grulla para que lo saque de su garganta, prometiendo pagarle, pero luego se niega a cumplir su promesa.',\n",
       "  'Subtema 1': 'La grulla arriesga su vida al meter su cabeza en la boca del lobo para ayudarlo, demostrando confianza y valentía.',\n",
       "  'Subtema 2': 'El lobo muestra ingratitud y malicia al no cumplir su promesa de pagar a la grulla por su ayuda.',\n",
       "  'Subtema 3': 'La fábula ilustra cómo, a menudo, los malvados no cumplen sus promesas, sin importar la ayuda que hayan recibido.'},\n",
       " 'audio05': {'Resumen': 'Un lobo hambriento intenta devorar a un caballo, pero su plan se ve frustrado cuando el caballo lo engaña para que se distraiga con un campo de cebada.',\n",
       "  'Subtema 1': 'La astucia del caballo muestra que la inteligencia puede superar la fuerza bruta de un enemigo malvado.',\n",
       "  'Subtema 2': 'La preferencia del lobo por la cebada refleja cómo el deseo puede nublar el juicio y llevar a decisiones insensatas.',\n",
       "  'Subtema 3': 'Los ruidos y los oídos atentos del lobo y el caballo destacan la importancia de prestar atención al entorno para protegerse de los peligros.'},\n",
       " 'audio06': {'Resumen': 'Un lobo utiliza su astucia y poder para imponer sus propias leyes y distribuir injustamente los recursos, demostrando que la fuerza a menudo prevalece sobre la justicia.',\n",
       "  'Subtema 1': 'La manipulación de las leyes por parte del lobo resalta cómo el poder puede corromper y distorsionar la justicia para beneficiar a los más fuertes.',\n",
       "  'Subtema 2': 'La figura del asno como personaje sumiso y obediente ilustra la vulnerabilidad de aquellos que carecen de poder frente a la autoridad arbitraria.',\n",
       "  'Subtema 3': 'La fábula critica la desigualdad en la distribución de recursos, mostrando cómo los más débiles a menudo son explotados por quienes ostentan el control.'},\n",
       " 'audio14': {'Resumen': 'Un cabrito burlón se siente seguro en su casa mientras un lobo intenta convencerlo de salir, revelando la importancia de la seguridad y el valor de la prudencia.',\n",
       "  'Subtema 1': 'La astucia del lobo al intentar persuadir al cabrito demuestra la importancia de no dejarse llevar por palabras engañosas.',\n",
       "  'Subtema 2': 'La seguridad del cabrito en su hogar destaca cómo el refugio y la protección son esenciales para evitar peligros.',\n",
       "  'Subtema 3': 'La interacción entre el lobo y el cabrito resalta el valor del autocontrol y la serenidad frente a situaciones amenazantes.'},\n",
       " 'audio22': {'Resumen': 'Un perro codicioso trata de comer huevos de almeja, pero al no estar acostumbrado, sufre las consecuencias de su imprudencia.',\n",
       "  'Subtema 1': 'La reflexión sobre cómo los impulsos mal controlados pueden llevar a situaciones perjudiciales.',\n",
       "  'Subtema 2': 'La importancia de reconocer las propias limitaciones y no dejarse llevar por deseos engañosos.',\n",
       "  'Subtema 3': 'El merecido castigo que a veces reciben quienes actúan sin pensar en las consecuencias de sus acciones.'},\n",
       " 'audio24': {'Resumen': 'Un perro pierde un trozo de carne al dejarse llevar por la ilusión de su reflejo en el río.',\n",
       "  'Subtema 1': 'La avaricia y el deseo por lo ajeno pueden llevar a la pérdida de lo que ya poseemos.',\n",
       "  'Subtema 2': 'La diferencia entre la realidad y las ilusiones puede ser engañosa y provocar resultados inesperados.',\n",
       "  'Subtema 3': 'La importancia de valorar lo propio y no dejarse llevar por supuestos beneficios mejorados.'},\n",
       " 'audio25': {'Resumen': 'Un perro astuto roba un trozo de carne de una carnicería mientras el carnicero está distraído, generando un accidente inesperado.',\n",
       "  'Subtema 1': 'La distracción del carnicero permite al perro aprovechar la oportunidad para huir con la carne.',\n",
       "  'Subtema 2': 'La amistad entre el perro y otro animal es puesta a prueba cuando el incidente ocurre.',\n",
       "  'Subtema 3': 'El carnicero reflexiona sobre el poder de la atención y la importancia de estar alerta en su trabajo.'},\n",
       " 'audio26': {'Resumen': 'Un perro orgulloso presume de su campanilla en la plaza, pero una perra sabia le recuerda que su presencia no es motivo de orgullo sino de advertencia sobre su maldad.',\n",
       "  'Subtema 1': 'La campanilla del perro simboliza una advertencia pública sobre su comportamiento dañino, más que un logro personal digno de presumir.',\n",
       "  'Subtema 2': 'La interacción entre el perro y la perra destaca la importancia de la sabiduría y la razón para desenmascarar la vanidad y el orgullo infundado.',\n",
       "  'Subtema 3': 'La fábula explora la diferencia entre la apariencia y la realidad, mostrando cómo los símbolos de estatus pueden ocultar verdades más profundas y menos halagadoras.'},\n",
       " 'audio27': {'Resumen': 'Un perro temeroso emprende una persecución tras un león, pero al afrontar el peligro, retrocede rápidamente al comprender su audacia imprudente.',\n",
       "  'Subtema 1': 'La valentía impulsiva puede convertirse en temor cuando se enfrenta la verdadera magnitud del desafío.',\n",
       "  'Subtema 2': 'A veces, perseguir un objetivo sin preparación puede llevar a la retirada ante la realidad del riesgo.',\n",
       "  'Subtema 3': 'La fuerza del león, simbolizada por su rugido, revela que no siempre se puede soportar una empresa temeraria sin consecuencias.'}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostramos los resúmenes y subtemas generados\n",
    "fable_summaries_and_subtopics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx-dZSFJz9cK"
   },
   "source": [
    "# **Ejercicio 6:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w3usdaC0BCj"
   },
   "source": [
    "En esta actividad tuvimos la oportunidad de transformar audios que contenían narraciones de fábulas con diferentes acentos a resúmenes que incluían subtemas de interés para cada una y empleamos el uso de diversas tecnologías del procesamiento de lenguaje natural para poder realizarlo. Tuvimos la oportunidad de emplear una API de OpenAI para la transcripción del audio a texto donde usamos el modelo de whisper-1. Posteriormente lo limpiamos empleando métodos que anteriormente habíamos usado para finalmente usar un modelo de lenguaje como el GPT-4 para generar resúmenes sintetizados. Un paso clave fue la extracción de palabras clave para las fábulas, puesto que usamos el algoritmo de LDA (Latent Dirichlet Allocation), lo que nos permite identificar palabras centrales para cada una.\n",
    "\n",
    "A su vez, también usamos los mismos procesos con otras fábulas donde tuvimos la oportunidad de tener un contexto más general por la gran diversidad de narraciones, pues en lugar de ser solo diez fueron veinte en total, lo que nos da una idea más clara y concisa de que nuestro procesamiento fue muy bueno, pues los resúmenes y creaciones de subtemas se notan muy buenos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CtB5Q3m41YQ0"
   },
   "source": [
    "# **Fin de la actividad LDA y LMM: audio-a-texto**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1BtP-Sk0DT-M",
    "6uYgtCvvJSmq",
    "NM0D83j8EWiN",
    "Blrrs1sWwkSx",
    "Kx-dZSFJz9cK"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
