{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBbWMn9ebmi8"
      },
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "### Tecnológico de Monterrey\n",
        "\n",
        "### Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "## **Actividad de las Semanas 5 y 6**\n",
        "### **Problema de asignación de créditos: South German Dataset.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiwEw8XsZG2W"
      },
      "source": [
        "## **Nombres y matrículas:**\n",
        "\n",
        "\n",
        "\n",
        "*   ### Hiram García Austria: A00378771\n",
        "\n",
        "*   ### Nombre y matrícula\n",
        "\n",
        "*   ### Nombre y matrícula\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUxxkjE6shkH"
      },
      "source": [
        "# **Parte I: Partición, análisis y pre-procesamiento de los datos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a08Di3GjkL1Y"
      },
      "source": [
        "## **Ejercicio 1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "6VGEpE4SblfD"
      },
      "outputs": [],
      "source": [
        "# Aquí deberás incluir todas las librerías que requieras durante esta actividad:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold, train_test_split, cross_validate\n",
        "from imblearn.metrics import geometric_mean_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "# Bosque aleatorio\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "K3gUzoM3iRkt"
      },
      "outputs": [],
      "source": [
        "# Si se desean comentar algunos de los Warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ppyf8TTgb9zq"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>status</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>18</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_history</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>purpose</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>amount</th>\n",
              "      <td>1049</td>\n",
              "      <td>2799</td>\n",
              "      <td>841</td>\n",
              "      <td>2122</td>\n",
              "      <td>2171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>savings</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>employment_duration</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>installment_rate</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>personal_status_sex</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_debtors</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>present_residence</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>property</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>21</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>39</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>other_installment_plans</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>housing</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number_credits</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>job</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>people_liable</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>telephone</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>foreign_worker</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>credit_risk</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            0     1    2     3     4\n",
              "status                      1     1    2     1     1\n",
              "duration                   18     9   12    12    12\n",
              "credit_history              4     4    2     4     4\n",
              "purpose                     2     0    9     0     0\n",
              "amount                   1049  2799  841  2122  2171\n",
              "savings                     1     1    2     1     1\n",
              "employment_duration         2     3    4     3     3\n",
              "installment_rate            4     2    2     3     4\n",
              "personal_status_sex         2     3    2     3     3\n",
              "other_debtors               1     1    1     1     1\n",
              "present_residence           4     2    4     2     4\n",
              "property                    2     1    1     1     2\n",
              "age                        21    36   23    39    38\n",
              "other_installment_plans     3     3    3     3     1\n",
              "housing                     1     1    1     1     2\n",
              "number_credits              1     2    1     2     2\n",
              "job                         3     3    2     2     2\n",
              "people_liable               2     1    2     1     2\n",
              "telephone                   1     1    1     1     1\n",
              "foreign_worker              2     2    2     1     1\n",
              "credit_risk                 1     1    1     1     1"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Carga y renombra los nombres de las columnas del alemán al inglés y desplegamos\n",
        "# de nuevo el DataFrame para ver el resultado obtenido:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "df = pd.read_csv('./SouthGermanCredit.asc', sep=' ')\n",
        "df.columns = [\n",
        "    'status',\n",
        "    'duration',\n",
        "    'credit_history',\n",
        "    'purpose',\n",
        "    'amount',\n",
        "    'savings',\n",
        "    'employment_duration',\n",
        "    'installment_rate',\n",
        "    'personal_status_sex',\n",
        "    'other_debtors',\n",
        "    'present_residence',\n",
        "    'property',\n",
        "    'age',\n",
        "    'other_installment_plans',\n",
        "    'housing',\n",
        "    'number_credits',\n",
        "    'job',\n",
        "    'people_liable',\n",
        "    'telephone',\n",
        "    'foreign_worker',\n",
        "    'credit_risk'\n",
        "]\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "df.head().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LckYCS8SlnFo"
      },
      "source": [
        "## **Ejercicio 2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Tlg8jYbnlqNA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "credit_risk\n",
            "1    700\n",
            "0    300\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Realiza a continuación una transformación para que la clase negativa (buen cliente)\n",
        "# quede con el valor de 0 y la clase positiva (mal cliente) quede con el valor de 1.\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "df['credit_risk'] = df['credit_risk'].replace({'1': 0, '0': 1})\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "print(df['credit_risk'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQx2lbzTkEsQ"
      },
      "source": [
        "## **Ejercicio 3**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "TP5-zdWVczhy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensiones:\n",
            "Entrenamiento: (700, 20) (700,)\n",
            "Prueba: (300, 20) (300,)\n",
            "\n",
            "Porcentaje clases Positiva:30.00%, y Negativa:70.00%\n"
          ]
        }
      ],
      "source": [
        "# Realiza una partición solicitada de entrenamiento y prueba.\n",
        "# Los nombres de los conjuntos deberán ser como se indican en los print de abajo:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "X = df.drop('credit_risk', axis=1)\n",
        "y = df['credit_risk']\n",
        "\n",
        "# Mismos porcentajes que se utilizaron en el artículo: 70% - 30%\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# Mostremos las dimensiones de la partición generada:\n",
        "print(\"Dimensiones:\")\n",
        "print(\"Entrenamiento:\", Xtrain.shape, ytrain.shape)\n",
        "print(\"Prueba:\", Xtest.shape, ytest.shape)\n",
        "\n",
        "# Y el porcentaje de cada clase de la variable de salida:\n",
        "tmp = ytrain.sum()/ytrain.shape[0]\n",
        "print(\"\\nPorcentaje clases Positiva:%.2f%%, y Negativa:%.2f%%\" % (100*(1-tmp),tmp*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptwAm_mOjVWH"
      },
      "source": [
        "### **Con base al porcentaje de los niveles de la variable de salida ¿podemos decir que tenemos un problema de datos desbalanceado? ¿Por qué?**\n",
        "\n",
        "\n",
        "\n",
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "Tenemos un problema de clases desbalanceadas ya que la clase positiva (mal cliente) es minoritaria (30%), mientras que la clase negativa (buen cliente) es mayoritaria (70%).\n",
        "\n",
        "Para resolver este problema podemos realizar un balanceo de las clases en el conjunto de entrenamiento con técnicas de sobre-muestreo en la clase minoritaria, o bien técnicas de sub-muestreo en la clase mayoritaria.\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto: +++++++++++\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocmGcSC2j_2x"
      },
      "source": [
        "## **Ejercicio 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5J2kIzLYHPZP"
      },
      "outputs": [],
      "source": [
        "# De acuerdo a la información de la Tabla 3 del artículo de la IEEE\n",
        "# define las variables correspondientes que se indican a continuación:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "# Variables numéricas:\n",
        "lista_paper_num = [\n",
        "    'duration',\n",
        "    'amount',\n",
        "    'age',\n",
        "    'people_liable'\n",
        "]\n",
        "\n",
        "# Variables ordinales:\n",
        "lista_paper_ord = [\n",
        "    'employment_duration',\n",
        "    'installment_rate',\n",
        "    'present_residence',\n",
        "    'property',\n",
        "    'number_credits',\n",
        "    'job'\n",
        "]\n",
        "\n",
        "# Variables nominales:\n",
        "lista_paper_cat = [\n",
        "    'status',\n",
        "    'credit_history',\n",
        "    'purpose',\n",
        "    'savings',\n",
        "    'personal_status_sex',\n",
        "    'other_debtors',\n",
        "    'other_installment_plans',\n",
        "    'housing',\n",
        "    'telephone',\n",
        "    'foreign_worker',\n",
        "]\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb5bE4WJj8Rw"
      },
      "source": [
        "## **Ejercicio 5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "NvNYiIp9weCm"
      },
      "outputs": [],
      "source": [
        "# Transformaciones que se aplicarán a las variables numéricas usando la clase Pipeline de sklearn:\n",
        "\n",
        "# ************* Incluye aquí tu código:*****************************\n",
        "\n",
        "# Variables numéricas:\n",
        "numericas_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MinMaxScaler())\n",
        "])\n",
        "numericas_pipe_nombres = lista_paper_num\n",
        "\n",
        "\n",
        "# Variables categóricas-Nominales:\n",
        "nominales_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))\n",
        "])\n",
        "nominales_pipe_nombres = lista_paper_cat\n",
        "\n",
        "# Variables categóricas-ordinales:\n",
        "ordinales_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('ordinal', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n",
        "])\n",
        "ordinales_pipe_nombres = lista_paper_ord\n",
        "\n",
        "# Conjuntas las transformaciones de todo tipo de variable y\n",
        "# deja sin procesar aquellas que hayas decidido no transformar:\n",
        "\n",
        "columnasTransformer = ColumnTransformer([\n",
        "    ('numericas', numericas_pipe, numericas_pipe_nombres),\n",
        "    ('nominales', nominales_pipe, nominales_pipe_nombres),\n",
        "    ('ordinales', ordinales_pipe, ordinales_pipe_nombres)\n",
        "], remainder='passthrough')\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJokj9Diyeu0"
      },
      "source": [
        "## **Ejercicio 6**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "d3lqBiH5wd1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dimensión de las variables de entrada ANTES de las transformaciones: (1000, 20)\n",
            "Dimensión de las variables de entrada DESPUÉS de las transformaciones: (1000, 41)\n"
          ]
        }
      ],
      "source": [
        "# Como se va a utilizar Validación-Cruzada, concatena los conjuntos de entrenamiento y prueba\n",
        "# en uno nuevo conjunto aumentado que llamaremos trainval para utilizar como entrenamiento:\n",
        "\n",
        "\n",
        "# ************* Incluye aquí tu código:**************************\n",
        "\n",
        "Xtraintest = pd.concat([Xtrain, Xtest], axis=0)\n",
        "ytraintest = pd.concat([ytrain, ytest], axis=0)\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *************\n",
        "\n",
        "\n",
        "# Veamos cuántas variables nuevas se introducen con las transformaciones One-Hot-Encoding:\n",
        "Xtmp = Xtraintest.copy()\n",
        "tmp = columnasTransformer.fit_transform(Xtmp)\n",
        "print(\"Dimensión de las variables de entrada ANTES de las transformaciones:\", Xtmp.shape)\n",
        "print(\"Dimensión de las variables de entrada DESPUÉS de las transformaciones:\", tmp.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZxyRbHL0gNF"
      },
      "source": [
        "## **Ejercicio 7**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "0hdi7AAtwd5G",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">> LR\n",
            "\t test_miaccuracy 0.752 (0.021)\n",
            "\t train_miaccuracy 0.787 (0.007)\n",
            "\t test_miprecision 0.797 (0.013)\n",
            "\t train_miprecision 0.819 (0.007)\n",
            "\t test_mirecall 0.842 (0.036)\n",
            "\t train_mirecall 0.875 (0.005)\n",
            "\t test_mifi 0.819 (0.018)\n",
            "\t train_mifi 0.846 (0.005)\n",
            "\t test_miauc 0.801 (0.023)\n",
            "\t train_miauc 0.847 (0.007)\n",
            "\t test_migmean 0.693 (0.022)\n",
            "\t train_migmean 0.732 (0.012)\n",
            ">> kNN\n",
            "\t test_miaccuracy 0.706 (0.024)\n",
            "\t train_miaccuracy 0.807 (0.007)\n",
            "\t test_miprecision 0.757 (0.019)\n",
            "\t train_miprecision 0.829 (0.008)\n",
            "\t test_mirecall 0.826 (0.038)\n",
            "\t train_mirecall 0.895 (0.008)\n",
            "\t test_mifi 0.789 (0.019)\n",
            "\t train_mifi 0.861 (0.005)\n",
            "\t test_miauc 0.717 (0.030)\n",
            "\t train_miauc 0.870 (0.008)\n",
            "\t test_migmean 0.619 (0.041)\n",
            "\t train_migmean 0.752 (0.012)\n",
            ">> DTree\n",
            "\t test_miaccuracy 0.687 (0.026)\n",
            "\t train_miaccuracy 1.000 (0.000)\n",
            "\t test_miprecision 0.768 (0.022)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.761 (0.030)\n",
            "\t train_mirecall 1.000 (0.000)\n",
            "\t test_mifi 0.764 (0.020)\n",
            "\t train_mifi 1.000 (0.000)\n",
            "\t test_miauc 0.650 (0.030)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.639 (0.034)\n",
            "\t train_migmean 1.000 (0.000)\n",
            ">> RF\n",
            "\t test_miaccuracy 0.760 (0.023)\n",
            "\t train_miaccuracy 1.000 (0.000)\n",
            "\t test_miprecision 0.785 (0.017)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.882 (0.034)\n",
            "\t train_mirecall 1.000 (0.000)\n",
            "\t test_mifi 0.830 (0.018)\n",
            "\t train_mifi 1.000 (0.000)\n",
            "\t test_miauc 0.812 (0.028)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.674 (0.031)\n",
            "\t train_migmean 1.000 (0.000)\n",
            ">> XGBoost\n",
            "\t test_miaccuracy 0.756 (0.023)\n",
            "\t train_miaccuracy 1.000 (0.000)\n",
            "\t test_miprecision 0.800 (0.017)\n",
            "\t train_miprecision 1.000 (0.000)\n",
            "\t test_mirecall 0.846 (0.030)\n",
            "\t train_mirecall 1.000 (0.000)\n",
            "\t test_mifi 0.822 (0.018)\n",
            "\t train_mifi 1.000 (0.000)\n",
            "\t test_miauc 0.809 (0.022)\n",
            "\t train_miauc 1.000 (0.000)\n",
            "\t test_migmean 0.698 (0.028)\n",
            "\t train_migmean 1.000 (0.000)\n",
            ">> MLP\n",
            "\t test_miaccuracy 0.753 (0.027)\n",
            "\t train_miaccuracy 0.788 (0.007)\n",
            "\t test_miprecision 0.791 (0.019)\n",
            "\t train_miprecision 0.816 (0.007)\n",
            "\t test_mirecall 0.856 (0.035)\n",
            "\t train_mirecall 0.880 (0.009)\n",
            "\t test_mifi 0.822 (0.021)\n",
            "\t train_mifi 0.847 (0.005)\n",
            "\t test_miauc 0.801 (0.025)\n",
            "\t train_miauc 0.846 (0.007)\n",
            "\t test_migmean 0.684 (0.033)\n",
            "\t train_migmean 0.729 (0.012)\n",
            ">> SVM\n",
            "\t test_miaccuracy 0.737 (0.028)\n",
            "\t train_miaccuracy 0.807 (0.006)\n",
            "\t test_miprecision 0.758 (0.020)\n",
            "\t train_miprecision 0.805 (0.009)\n",
            "\t test_mirecall 0.890 (0.032)\n",
            "\t train_mirecall 0.937 (0.009)\n",
            "\t test_mifi 0.818 (0.020)\n",
            "\t train_mifi 0.866 (0.004)\n",
            "\t test_miauc 0.794 (0.027)\n",
            "\t train_miauc 0.874 (0.006)\n",
            "\t test_migmean 0.619 (0.042)\n",
            "\t train_migmean 0.714 (0.017)\n"
          ]
        }
      ],
      "source": [
        "# Definimos a continuación la función que llamamos \"mis_modelos\" que incluye\n",
        "# todos los modelos que deseamos comparar en el ejercicio.\n",
        "\n",
        "\n",
        "def mis_modelos():\n",
        "  modelos, nombres = list(), list()\n",
        "\n",
        "\n",
        "  # ************* Incluye aquí tu código:**************************\n",
        "  #\n",
        "  # Deberás incluir en cada modelo los argumentos que consideres\n",
        "  # adecuados para que cada uno converja y no esté sobre-entrenado\n",
        "  # con respecto a la métrica de la exactitud (accuracy).\n",
        "\n",
        "\n",
        "  # Regresión Logística - Logistic Regression-LR:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "  # Este valor de \"penalty\" no se debe de cambiar, ya que define el modelo sin regularización.\n",
        "  modelos.append(LogisticRegression(penalty=None, solver='lbfgs', max_iter=2000, random_state=1))\n",
        "  nombres.append('LR')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # k-Vecinos más Cercanos : k-Nearest-Neighbors-kNN:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
        "\n",
        "  modelos.append(KNeighborsClassifier())\n",
        "  nombres.append('kNN')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Árbol de decisiones-DecisionTree-DT:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
        "\n",
        "  modelos.append(DecisionTreeClassifier(max_depth = None,       # None, 5, 3, 1\n",
        "                                        min_samples_split=2,   # 2,3,5, 20\n",
        "                                        #min_samples_leaf=1,  # trata al inicio de usar solo uno de estos, split o leaf, para su mejor comprensión.\n",
        "                                        #random_state=7\n",
        "                                        ))\n",
        "  nombres.append('DTree')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Bosque Aleatorio-RandomForest-RF:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "  modelos.append(RandomForestClassifier(n_estimators= 100,    # 100\n",
        "                                        max_depth= None,      # None, 1, 2,3, 4, 5, 6 ... ¿Se esperaría la misma profunidad en un RF y en un DT?\n",
        "                                        min_samples_split=2,    # 2, 5, 15\n",
        "                                        #random_state=0\n",
        "                                        ))\n",
        "  nombres.append('RF')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # XGBoosting:\n",
        "  # https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBClassifier\n",
        "  # https://xgboost.readthedocs.io/en/stable/parameter.html\n",
        "\n",
        "  modelos.append(XGBClassifier(booster= 'gbtree',\n",
        "                               n_estimators=100,   # A medida que se aumente \"n_estimators\", se debe disminuir el \"learning_rate\", de manera general.\n",
        "                               max_depth= 6,             # 1,3, 6,\n",
        "                               learning_rate=0.3,   #  0.3, 0.000001, 0.01, 100,     # participación o peso de cada árbol desde el inicio.\n",
        "                               subsample=1.0,        # 1.0,  0.9, 0.8, ... 0.5    # submuestreo con respecto a los renglones para evitar overfitting.\n",
        "                               #random_state=5,\n",
        "                               objective='binary:logistic',\n",
        "                               n_jobs=-1))\n",
        "  nombres.append('XGBoost')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Red neuronal de Perceptrón Multicapa-MLP:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
        "\n",
        "  modelos.append(MLPClassifier(hidden_layer_sizes=(30,),     # 100,  6, 24, 30, (15,15), (50,50)\n",
        "                               activation='logistic',\n",
        "                               max_iter=1000,                  # 200,\n",
        "                               alpha=0.0001,               # término de regularización L2.\n",
        "                               #learning_rate='constant',       # tasa de aprendizaje o tamaño de paso del método Gradiente Descendente.\n",
        "                               #learning_rate_init=0.001,\n",
        "                               #random_state=1\n",
        "                               ))\n",
        "  nombres.append('MLP')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Máquina de Vectores de Soporte-SVM:\n",
        "  # https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
        "\n",
        "  modelos.append(SVC(kernel='rbf',\n",
        "                     C= 1.0,      # 1.0, 0.00001, 1000           # inversamente proporcional a la constante de regularización L2.\n",
        "                     gamma= 'scale',           # scale,  0.005\n",
        "                     #class_weight='balanced',     # Siempre puedes hacer uso del balanceo en caso de que ayude.\n",
        "                     #random_state=7\n",
        "                     ))\n",
        "  nombres.append('SVM')\n",
        "\n",
        "  return modelos, nombres\n",
        "\n",
        "\n",
        "# Técnica de sub muestreo (under sampling) y/o sobre muestreo (oversampling) utilizada:\n",
        "mi_uoSampling = SMOTE(sampling_strategy=0.5, random_state=42) # Aplicando una relación de 50% de la clase minoritaria.\n",
        "\n",
        "Xtv_uo, ytv_uo = mi_uoSampling.fit_resample(Xtraintest, ytraintest)\n",
        "\n",
        "\n",
        "\n",
        "# *********** Aquí termina la sección de agregar código *******************\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Entrenamos cada uno de los modelos y desplegamos la métricas de Train y Val.\n",
        "\n",
        "# NOTA: Observa que el método de Validación-Cruzada llama  a los resultados\n",
        "#       de \"validation\" como \"test\":\n",
        "\n",
        "modelos, nombres = mis_modelos()\n",
        "resultados = list()\n",
        "\n",
        "for i in range(len(modelos)):\n",
        "\n",
        "  # Definimos nuestro pipeline con las transformaciones y los modelos:\n",
        "  pipeline = Pipeline(steps=[('ct',columnasTransformer),('m',modelos[i])])\n",
        "\n",
        "  # Aplicaremos validación-cruzada:\n",
        "  micv = RepeatedStratifiedKFold(n_splits=5,\n",
        "                                 n_repeats=3,\n",
        "                                 random_state=5     # agreguemos una semilla para estabilizar resultados.\n",
        "                                 )\n",
        "\n",
        "\n",
        "  # Definimos las métricas que desamos recuperar:\n",
        "  mismetricas = {'miaccuracy':'accuracy','miprecision':'precision','mirecall':'recall',\n",
        "                 'mifi':'f1','miauc':'roc_auc','migmean':make_scorer(geometric_mean_score)}\n",
        "\n",
        "  # Llevamos a cabo el entrenamiento:\n",
        "  scores = cross_validate(pipeline,\n",
        "                          Xtv_uo,\n",
        "                          ytv_uo,\n",
        "                          scoring=mismetricas,\n",
        "                          cv=micv,\n",
        "                          return_train_score=True,\n",
        "                          )\n",
        "\n",
        "  # Guardemos el resultado de cada modelo para análisis posteriores.\n",
        "  resultados.append(scores)\n",
        "\n",
        "  # Desplegamos los valores de las métricas para verificar si no hay\n",
        "  # subentrenamiento o sobreentrenamiento:\n",
        "  print('>> %s' % nombres[i])\n",
        "  for j,k in enumerate(list(scores.keys())):\n",
        "    if j>1:\n",
        "      print('\\t %s %.3f (%.3f)' % (k, np.mean(scores[k]),np.std(scores[k])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JkGo57zMXqn"
      },
      "source": [
        "## **Ejercicio 8**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n04HnK-ZX4vl"
      },
      "source": [
        "### **Escribe tus conclusiones finales de la actividad.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7s7iDgKYEn9"
      },
      "source": [
        "### ++++++++ Inicia la sección de agregar texto: +++++++++++\n",
        "\n",
        "\n",
        "## **Conclusiones sobre los resultados obtenidos**\n",
        "* A pesar de que en la precisión, el mejor modelo es el Random Forest (RF) con 0.76, el modelo XGBoost tiene el segundo mejor desempeño con 0.756 (casi igual).\n",
        "* En cuanto a la media geométrica, el modelo XGBoost tiene el mejor desempeño con 0.698.\n",
        "* En cuanto al area bajo la curva (AUC), el modelo XGBoost tiene también el mejor desempeño con 0.809.\n",
        "* En general XGBoost tiene el mejor desempeño en todas las métricas, por lo que consideramos que es el mejor modelo para este escenario.\n",
        "* Como un pequeño detalle, respecto al tiempo de ejecución, el modelo XGBoost es el que más tiempo tarda en ejecutarse, pero consideramos que vale la pena por el desempeño que tiene.\n",
        "\n",
        "\n",
        "### ++++++++ Termina la sección de agregar texto. +++++++++++\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-tW_CdUYMdl"
      },
      "source": [
        ">> ### **Fin de la Actividad de las Semanas 5 y 6.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "a08Di3GjkL1Y",
        "LckYCS8SlnFo",
        "qQx2lbzTkEsQ",
        "ocmGcSC2j_2x",
        "zb5bE4WJj8Rw",
        "UJokj9Diyeu0",
        "hZxyRbHL0gNF",
        "4JkGo57zMXqn"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
